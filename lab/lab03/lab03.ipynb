{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3:  Bayesian Estimation in Hierarchical Graphical Models\n",
    "Welcome to the third Data 102 lab! \n",
    "\n",
    "The goal of this lab is to go over Bayesian Estimation and provide an introduction to Hierarchial Graphical Models.\n",
    "\n",
    "The code and responses you need to write are commented out with a message **\"TODO: fill ...\"**. There is additional documentation for each part as you go along.\n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "## Gradescope Submission\n",
    "To submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "\n",
    "**We encourage you to finish this assignment by Thursday, Feb. 11.**\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Sunday, Feb 14, 2021 at 11:59 PM. PST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import beta, binom\n",
    "import itertools\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "import hashlib\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def get_hash(num, significance = 4):\n",
    "    num = round(num, significance)\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0: Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0a) The Bayesian posterior risk is a function of the data. True or False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans0a = # TODO: fill in either True or False as a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(get_hash(ans0a) == 'c4ca4238a0b923820dcc509a6f75849b')\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0b)\n",
    "\n",
    "Suppose in a 1-dimensional linear regression, you have as your model $y = bx + \\epsilon$ with $\\epsilon \\sim N(0, \\sigma^2)$, a scalar regression weight $b \\sim N(0, \\sigma_{b}^2)$, and scalar data point $x$.  What is the distribution of $y$ given $b$ and $x$? In other words, $y|b, x \\sim$ \\___\\___\\_____?\n",
    "\n",
    "Note: Fill in the blank with both the distribution and the corresponding parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "`TODO: fill in with your answer.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0c) Risk can be understood as the expected loss. True or False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans0c = # TODO: fill in either True or False as a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(get_hash(ans0c+1) == 'c81e728d9d4c2f636f067f89cc14862c')\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Beta-Binomial Graphical Model\n",
    "\n",
    "In this question we will look at the COVID modeling example from one of the optional lecture videos. Here's the summary of what you need to know:\n",
    "\n",
    "In this problem we are trying to estimate the COVID infection risk in households. To do that we curate a list of K studies. Each study has an associated pair $(N_i, X_i)$ where $N_i$ denotes the number of susceptible individuals considered and $X_i$ is the number of them that became infected. In our modeling assumptions we assume that each susceptible person gets infected with probability $\\theta_i$. In epidemiology, this quantity is known as Secondary Attack Rate, or SAR for short.\n",
    "\n",
    "We're trying to do two things: \n",
    "1. We want to *combine* the information from all the studies, so we can get a better estimate of SAR than we would with any individual study on its own. \n",
    "2. We want to understand why the studies got different results: Specifically, we'd like to figure out the regions with the *lowest* SAR, so that we can investigate what contributed to their relative success. In the other direction, we want to know which regions had the *highest* SAR, since they're likely the ones most urgently in need of intervention measures to help slow the spread.\n",
    "\n",
    "For more information, you can always watch the [video from the lecture 7 playlist](https://www.youtube.com/watch?v=Gq9AhZYk8wk&list=PLSEfoRJ1f3UOcSxA5ORZ3RRRiGiQ0DAS5&index=7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read out a dataset \n",
    "study_df = pd.read_csv(\"study_df.csv\", header=0)\n",
    "study_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a Compute the trivial estimate of SAR\n",
    "\n",
    "\n",
    "The most straingforward way to estimate the probability of infection (SAR) is to divide the number of infected cases by the number of susceptible cases. \n",
    "\n",
    "Compute this quantity in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the function\n",
    "def trivial_theta_estimate(N_value, X_value):\n",
    "    \"\"\"\n",
    "    Computes the trivial estimate of the Secondary Attack Rate\n",
    "    \n",
    "    Inputs:\n",
    "        N_value : int, number of susceptible individuals\n",
    "        X_value : int, number of infected individuals\n",
    "        \n",
    "    Output:\n",
    "        theta_est : float, estimate of probability of infection (SAR)\n",
    "    \"\"\"\n",
    "    theta_est = # TODO: fill in\n",
    "    return theta_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests\n",
    "n_test_array = [10, 100, 1000]\n",
    "x_test_array = [10, 34, 852]\n",
    "res_array = [trivial_theta_estimate(n, x_test_array[i]) for i,n in enumerate(n_test_array)]\n",
    "hash_list=['e4c2e8edac362acab7123654b9e73432','149dd5056939405870c9bb50cbc8691c','83659da620f470d5a131b5a9c76cfee7']\n",
    "for i,res in enumerate(res_array):\n",
    "    assert get_hash(res) == hash_list[i]\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\n",
    "study_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)\n",
    "study_df.sort_values('Trivial estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trivial estimates suggest that both minimum and maximum probabilities of infection correspond to small studies.**\n",
    "\n",
    "|      | Max     | Min     |\n",
    "|------|---------|---------|\n",
    "| Name | Study 1 | Study 2 |\n",
    "| X    | 2       | 8       | \n",
    "| N    | 11      | 12      |\n",
    "|$\\theta$| 0.18  | 0.50    |\n",
    "\n",
    "\n",
    "Intuitively, we probably shouldn't be making policy decision based on such small studies alone, especially when this dataset has other studies with tens or even hundreds of people. We would like to balance between strong evidence from the small studies and high confidence in estimates from larger studies.\n",
    "\n",
    "Bayesian inference provides a flexible framework to balance our apriori beliefs with new evidence. Consider the following graphical model:\n",
    "\n",
    "\n",
    "![](GM1.png)\n",
    "\n",
    "\n",
    "Note that this graphical model looks a little different from the one you saw in the lecture videos. Just like what you've already seen, the circles represent random variables, and shaded circles represent observed random variables. The diamond at the top represents fixed, unknown parameters . You'll also see people draw dots or squares for these: there isn't really one consistent notation.\n",
    "\n",
    "Here are a few important quantities in Bayesian inference. This lingo will be used at length in this course and in anything you'll learn in the future about Bayesian inference, so make sure you get familiar with it.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Joint Density / Joint Distribution:\n",
    "The structure of the graphical model specified the full joint density of the parameters and data in the model. For this example the join density is:\n",
    "$$p(\\theta_1, \\theta_2, \\ldots, \\theta_K, X_1, \\ldots, X_K) = \\prod_{\\text{vertex $V$ in graph}}p(V|\\text{parent of $V$}) = \\prod_{i=1}^K \\underbrace{p(\\theta_i|\\alpha, \\beta)}_{\\text{prior of $\\theta_i$}} \\prod_{i=1}^K \\underbrace{p(X_i|\\theta_i)}_{\\text{likelihood of data $X_i$}}$$\n",
    "\n",
    "The factorization of the joint density into products of priors and likelihoods is the key feature of Hierarchical Models. It allows to take a complex $2K$-dimensional joint probability and factorize it into products of 1-dimensional probabilities. This factorization is useful because it lets us simplify the distribution and control the amount of computation we have to do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Prior:  $\\theta_i \\sim Beta(\\alpha, \\beta)$\n",
    "\n",
    "We have the prior distribution:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\theta_i) \n",
    "    &= \\theta_i^{\\alpha-1}(1-\\theta_i)^{\\beta-1} \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)+\\Gamma(\\beta)} \\\\\n",
    "    &\\propto_{\\theta_i}\\theta_i^{\\alpha-1}(1-\\theta_i)^{\\beta-1}\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "where $\\Gamma$ is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function). Since $\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)+\\Gamma(\\beta)}$ does not depend on the value of $\\theta$. It is a scaling factor that ensures that $p(\\theta_i)$ is a valid probability function. This leads to a common notation in practice: $p(\\theta_i)\\propto_{\\theta_i}\\theta_i^{\\alpha-1}(1-\\theta_i)^{\\beta-1}$. The symbol $\\propto_{\\theta_i}$ means _proportional in $\\theta_i$_. This is a little more explicit than the $\\propto$ notation that you usually see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood: $X_i|\\theta \\sim Binomial(N_i, \\theta_i)$\n",
    "\n",
    "We'll use the notation $p(X_i|\\theta)$ for the likelihood function, which represents our belief about the distribution of the data if we know what the parameter $\\theta$ is (in other words, if we condition on $\\theta$).\n",
    "$$p(X_i|\\theta_i) = \\binom{N_i}{X_i} \\theta_i^{X_i}(1-\\theta_i)^{N_i - X_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal: Unconditional distribution of $X_i$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(X_i)\n",
    "    &= \\int_{\\theta_i} \\overbrace{p(X_i, \\theta_i)}^{\\text{joint distribution}} \\\\\n",
    "    &= \\int_0^1 \\underbrace{p(X_i|\\theta_i)}_{\\text{likelihood}} \\,\\underbrace{p(\\theta_i)}_{\\text{prior}} \\,d\\theta_i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This is the marginal distribution over the data: we can plug in a particular set of $X_i$ values and get out the probability that our model assigns to those values, averaged over all possible values of $\\theta$.\n",
    "\n",
    "When formulating a model, we usually choose the prior and the likelihood based on what we know about the problem. This means that computing this marginal distribution over $X_i$ requires *marginalizing* over the parameter $\\theta$: that involves either a summation or an integral (in this case it's an integral because $\\theta$ is continuous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior: $\\theta_i|X_i$\n",
    "The goal of many estimation problems is to obtain the posterior distribution of the parameter of interest $\\theta_i$ conditioned on the data $X_i$.\n",
    "\\begin{align}\n",
    "p(\\theta_i|X_i) &= \\frac{p(X_i|\\theta_i)p(\\theta_i)}{p(X_i)} \\quad \\text{(by Bayes Rule)}\\\\\n",
    "&\\propto_{\\theta} p(X_i|\\theta_i)p(\\theta_i) \\quad \\text{(the data marginal $p(X_i)$ does not depend on $\\theta$)}\\\\\n",
    "&\\propto_{\\theta}  \\underbrace{\\theta_i^{X_i}(1-\\theta_i)^{N_i - X_i}}_{\\text{likelihood}} \\underbrace{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}_{\\text{prior}}\\\\\n",
    "&\\propto_{\\theta}\\theta_i^{\\alpha + X_i - 1}(1-\\theta_i)^{\\beta + N_i - X_i - 1} \\quad \\text{unnormalized Beta density}\\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence $\\theta_i|X_i \\sim Beta(\\alpha + X_i, \\beta + N_i - X_i)$\n",
    "\n",
    "\n",
    "The fact that the posterior probability comes from the same distribution family is known as *conjugacy*. It is a very useful property because it allows us to compute the posteriors in close form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b (i) When specifying a Bayesian model, we use our domain knowledge to establish certain distributions, and then we use computation to find other ones. Which of the following do we establish using our domain knowledge? Pick all that apply.\n",
    "\n",
    "(a) Prior\n",
    "\n",
    "(b) Likelihood\n",
    "\n",
    "(c) Marginal distribution of the data\n",
    "\n",
    "(d) Posterior "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "`TODO: fill in with the relevant letters above`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Examine the prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta(alpha_value, beta_value):\n",
    "    x = np.arange(0, 1.01, 0.01)\n",
    "    y = beta.pdf(x, alpha_value, beta_value)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(r'$\\theta_i$')\n",
    "    plt.ylabel(r'$p(\\theta_i)$')\n",
    "    plt.title(r'Beta distribution with parameters $\\alpha$ and $\\beta$')\n",
    "    plt.ylim(0, 10)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c (i) Fix `alpha_value = 5`, and experiment with different values of `beta_value`. Write 1 sentence of your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c (ii) Fix `beta_value = 5`, and experiment with different values of `alpha_value`. Write 1 sentence of your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c (iii) Set `alpha_value = beta_value = 1`, increase their value such that `alpha_value=beta_value`. Write 1 sentence of your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d Compute Posterior Mean Estimates for SAR\n",
    "In Problem 2 of Discussion 3 we showed that the **posterior mean** minimizes the **Bayes Risk** for the **Squared Error Loss**.\n",
    "\n",
    "#### In the cell below write a function that computes the posterior mean corresponding to $\\theta_i|X_i$.\n",
    "\n",
    "*Hint: If you need to look up facts about certain well-known distributions, you can always (a) go to textbooks from classes you've taken before, (b) look on Wikipedia, or (c) do a simple web search.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def posterior_mean_estimate(N_value, X_value, alpha_value, beta_value):\n",
    "    \"\"\"\n",
    "    Computes the posterior E[theta_i|X_i] when we consider a prior theta_i ~ Beta(alpha, beta)\n",
    "    \n",
    "    Inputs: \n",
    "        N_value : int, total number of susceptible individuals\n",
    "        X_value : int, number of individuals that became infected\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "    \"\"\"\n",
    "    posterior_mean = # TODO: fill in\n",
    "    return posterior_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests\n",
    "N_test = 100\n",
    "X_test = 20\n",
    "alpha_test_array = [1, 10, 100]\n",
    "beta_test_array = [1, 10, 100]\n",
    "inputs = list(itertools.product(alpha_test_array, beta_test_array))\n",
    "hash_list = ['8ae3cf8f9366cbdea2ccf7706546ba4a','f8ddc3234c0a54e55b01384bcfb23f90','82589ee1f18a2e0b9fe9d14836983102',\n",
    "             '08cf5a2033e7e21ec90b6707c24facaf','70da82175ec8a195a3d8b0fa8f69681d','ced20bed08ecfba035cbc3e06657cff2',\n",
    "             'c8a7feeaced214c662a999d9bf075e8c','790abc5c38e7c740420b03c24fabb05b','54fbf38cf649866815e0fefc46a1f6c7']\n",
    "for i,inp in enumerate(inputs):\n",
    "    assert hash_list[i] == get_hash(posterior_mean_estimate(N_test, X_test, *inp))\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.e Examine the posterior mean estimate\n",
    "\n",
    "Let's assume that from domain knowledge, we think that the probability of infection (SAR) is close to $\\frac{1}{3}$. We pick a prior distribution for $\\theta_i$s that has mean $\\frac{1}{3}$. Any distribution of the form $\\theta_i \\sim Beta(k, 2k)$ has this property. The value of $k$ determines the 'strength' of the prior. Low values of $k$  correspond to 'flatter' priors, while larger values of $k$ correspond to 'peakier' priors. Play with the sliders in **1.b** to convince yourself.\n",
    "\n",
    "**Examine the plotting function below and answer the qualitative questions in the next cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify: Examine the code\n",
    "def plot_thetas(k):\n",
    "    \n",
    "    study_df[\"bayesian_theta\"] = study_df.apply(\n",
    "        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n",
    "        axis=1\n",
    "    )\n",
    "    study_df[\"trivial_theta\"] = study_df.apply(\n",
    "        lambda row: trivial_theta_estimate(row['N'], row['X']), \n",
    "        axis=1\n",
    "    )\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    graph = sns.scatterplot(\n",
    "        x=\"trivial_theta\", y=\"bayesian_theta\", \n",
    "        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x='trivial_theta', y='trivial_theta', \n",
    "        data= study_df, ls=\"--\", color='black', lw=1\n",
    "    )\n",
    "    plt.ylim(0.16, 0.52)\n",
    "    graph.axhline(\n",
    "        1/3, color='black', \n",
    "        label = \"$\\frac{1}{3}$ Prior Expectation\"\n",
    "    )\n",
    "    plt.xlabel('Trivial Estimate')\n",
    "    plt.ylabel('Posterior Mean Estimate')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    x = np.arange(0,1.01,0.01)\n",
    "    y = beta.pdf(x, k, 2*k)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(r'$\\theta_i$')\n",
    "    plt.ylabel(r'$p(\\theta_i)$')\n",
    "    plt.title(rf'Prior: $Beta(\\alpha={k}, \\beta={2*k})$')\n",
    "    plt.ylim(0, 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above the horizontal dashed line represents the prior mean estimate $\\mathbb{E}[\\theta_i] = \\frac{k}{k+2k} = 1/3$. The diagonal solid line marks $x=y$. Each data-point corresponds to a study, the size of the marker denotes the number of susceptible individuals in each study. Such that larger markers correspond to larger studies.\n",
    "\n",
    "**Answer the following questions with 1-2 sentences each.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d (i) Set $k=0$, what do you notice about the data points? Increase steadily the value of $k$. What happens with the points above the solid horizontal line? What about the points below it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d (ii) As you increase $k$, which points move faster, larger or slower ones? How can you explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d (iii) Imagine that we let $k\\to \\infty$. How do you think the two graphs above will look in the limit $k\\to \\infty$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d (iv) Fill in the blank in this sentence with either \"small\" or \"large\", and explain your answer: \n",
    "\n",
    "*If we're very sure that the true SAR is close to $\\frac{1}{3}$, we should choose a _______ value of $k$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Computational Approximate Inference\n",
    "\n",
    "In the previous question we looked at a Beta-Binomial Graphical model. We took advantage of the conjugacy properties of the model and were able to compute closed form solutions for the posterior mean estimates.\n",
    "\n",
    "However, as we introduce more complexity to the model, the conjugacy property quickly breaks and we have to resort to approximate inference. In this class, we'll focus primarily on *sampling* for approximate inference: this will be the topic of the next few lectures and next week's labs. In sampling-based approaches, we don't even try to get the exact posterior: instead, we generate a bunch of samples from it, and use those to approximate the distribution.\n",
    "\n",
    "In this question you will get a taste for probabilistic programming using `PyMC3`. Spend some time perusing the [documentation](https://docs.pymc.io/), but don't worry if it doesn't fully make sense just yet. We'll be using PyMC3 to run an algorithm called Markov Chain Monte Carlo (MCMC), which you'll learn about this week. We'll start by using the same model from Q.1, and compare the results from MCMC with the exact solutions we calculated above. Then, we'll add an extra parameter to the model and make things more complex: even though we can no longer compute our posterior in closed form, MCMC will still generate samples that we can use to estimate the $\\theta_i$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyMC3, and create a dummy model so that one-time initialization\n",
    "# happens while you're reading over the code in the next cell.\n",
    "\n",
    "# Note: this and the following cells may take a while to run\n",
    "\n",
    "# You can ignore the output of this cell.\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    dummy = pm.Beta('dummy', alpha=1, beta=1)\n",
    "    pm.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify: Spend some time examining the code\n",
    "def approximate_inference_MCMC(\n",
    "    alpha_value, beta_value, study_df = study_df\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates and generates samples from a PyMC3 model of\n",
    "    the posterior distribution that corresponds to the\n",
    "    graphical model in Q.1, using Markov Chain Monte Carlo (MCMC)\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of\n",
    "        the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "    \n",
    "    Outputs: (model, trace)\n",
    "        model is a PyMC3 model object, which represents the graphical model\n",
    "        trace is a PyMC3 trace object, which represents 2000 samples\n",
    "            of everything from the posterior\n",
    "    \"\"\"\n",
    "    # Defines the graphical model\n",
    "    with pm.Model() as model:\n",
    "        # The prior for theta is a Beta distribution with parameters\n",
    "        # alpha and beta, and there's one for each study.\n",
    "        theta = pm.Beta(\n",
    "            'theta', alpha=alpha_value, beta=beta_value, \n",
    "            shape=len(study_df)\n",
    "        )\n",
    "        \n",
    "        # The likelihood for X is binomial, with parameter p=theta,\n",
    "        # observed counts in study_df['X'], and observed N similarly\n",
    "        X = pm.Binomial(\n",
    "            'X', p=theta, observed=study_df['X'], n=study_df['N']\n",
    "        )\n",
    "        \n",
    "        # Generate samples from the posterior distribution using : run 4\n",
    "        # Markov chains of sampling in parallel, generating 500 samples\n",
    "        # each.\n",
    "        trace = pm.sample(500, chains=4, tune=1000, target_accept=0.95)\n",
    "    \n",
    "    return (model, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run approximate inference\n",
    "model, trace = approximate_inference_MCMC(10, 20)\n",
    "\n",
    "# Get posterior samples of theta\n",
    "thetas = trace['theta']\n",
    "thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Using the output of PyMC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a histogram of all 2,000 posterior samples for $\\theta_2$ (the SAR for Study 2). How do the samples compare to the two different estimates you saw in Question 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in\n",
    "plt.hist(..., density=True); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Compute Posterior Mean Estimates from Samples\n",
    "\n",
    "Fill in the function that computes posterior mean estimates for $\\theta_i$s for different parameters $\\alpha, \\beta$ of the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def empirical_posterior_mean_estimates(alpha_value, beta_value, study_df = study_df):\n",
    "    \"\"\" \n",
    "    Computes posterior mean estimates of theta_i by performing approximate inference\n",
    "    and then sampling from the posterior distribution:\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "        \n",
    "    Output:\n",
    "        posterior_estimates : (num_studies,) 1-D array of the same length as the \n",
    "            number of studies. posterior_estimates[i] contains the \n",
    "            mean estimate for theta_i based on running MCMC\n",
    "    \n",
    "    \"\"\"\n",
    "    posterior_estimates = # TODO: fill in\n",
    "    return posterior_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "posterior_estimates_test = empirical_posterior_mean_estimates(10,25)\n",
    "hash_list = [[\"e85b79abfd76b7c13b1334d8d8c194a5\"],\n",
    "            [\"261943f3a93b683ceeac658927f3923f\"],\n",
    "            [\"149dd5056939405870c9bb50cbc8691c\"],\n",
    "            [\"ba6197788db60f5e2cb45cd403fa6559\"],\n",
    "            [\"246c0903b5a64b2a854ec1e7865f174f\"],\n",
    "            [\"ffa243f771800363714f6055d9236fd6\"],\n",
    "            [\"ffa243f771800363714f6055d9236fd6\", \"9f4721cf71c0ed18cd60356036b953cc\"],\n",
    "            [\"45efc23f34e05a9ea4f5024988047dd6\"],\n",
    "            [\"8f11bfb91ec29936603314c7cbc46119\"],\n",
    "            [\"a3f2a910685f5b07f5f45a5fc1fdb389\"],\n",
    "            [\"91afec64e32d6bf957e441df2ab638bb\"],\n",
    "            [\"8ce3fac7e23a02ab4e00cf0f1e03310a\"]]\n",
    "print()\n",
    "\n",
    "for i, est in enumerate(posterior_estimates_test):\n",
    "    print(\"Study {}: {:.3f} \".format(i, est))\n",
    "    \n",
    "for i, est in enumerate(posterior_estimates_test):\n",
    "    assert get_hash(est, 2) in hash_list[i]\n",
    "\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c Plot the theoretical distribution of the posterior from Question 1 and the empirical distribution of the posterior from Question 2.\n",
    "\n",
    "Make a 4x3 plot such that each subplot corresponds to a study. \n",
    "\n",
    "Each subplot should contain 2 curves and a frequency histogram:\n",
    "- The PDF of the prior distribution of $\\theta_i$\n",
    "- The PDF of the true posterior distribution $\\theta_i|X_i$ computed in closed form, as in Q.1\n",
    "- The histogram of posterior samples of $\\theta_i|X_i$ computed in Q.2\n",
    "\n",
    "Make sure that you properly label each curve and histogram and give each subplot a meaningful title.\n",
    "\n",
    "To give you a mental image of what we have in mind here is a sample subplot. Don't worry if the colors in yours are different.\n",
    "\n",
    "![](sample_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write the plotting function\n",
    "def plot_densities(alpha_value, beta_value, study_df = study_df): \n",
    "    \"\"\"\n",
    "    Plots for each study the prior distribution, true posterior,\n",
    "    and histogram of posterior samples using MCMC\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "        \n",
    "    Outputs:\n",
    "        fig : Figure with 12 subplots\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(4, 3)\n",
    "    fig.set_figheight(15)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    \n",
    "    theta = np.arange(0, 1.01, 0.01)\n",
    "    prior = beta.pdf(theta, alpha_value, beta_value)\n",
    "    \n",
    "    model, trace = ... #TODO: Fill in\n",
    "    samples = ... #TODO: Fill in\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(3):\n",
    "            idx = 3*i+ j\n",
    "            X_i = study_df.loc[idx, 'X']\n",
    "            N_i = study_df.loc[idx, 'N']\n",
    "            study_name = f'Study {idx}'\n",
    "            true_posterior = beta.pdf(theta, ..., ...) #TODO: Fill in\n",
    "            \n",
    "            ax = axs[i, j]\n",
    "            ax.plot(theta, prior, label = 'Prior')\n",
    "            ax.plot(theta, true_posterior, label = \"Theoretical Posterior\")\n",
    "            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n",
    "            ax.set_title(study_name)\n",
    "            ax.legend()\n",
    "    \n",
    "    plt.tight_layout()        \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting densities for a weak prior\n",
    "fig1 = plot_densities(2, 4, study_df = study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting densities for a strong prior\n",
    "fig2 = plot_densities(20, 40, study_df = study_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b (i) Compare the curve of the theoretical distribution with the histogram of samples from the empirical posterior. Are they similar or different? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b (ii) Compare the two figures corresponding to 'weak' prior $\\theta_i \\sim Beta(2,4)$ and 'strong' prior  $\\theta_i \\sim Beta(20,40)$. How are they different? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d Approximate Inference for a More Complex Model\n",
    "\n",
    "The previous 2 parts served as a sanity check that the approximate inference techniques used by PyMC3 can approximate the theoretical posterior. The usefulness of such packages becomes apparent when we are dealing with more complex models that don't have conjugacy properties.\n",
    "\n",
    "Consider the following graphical model:\n",
    "\n",
    "![](GM2.png)\n",
    "\n",
    "Recent studies have shown that a large fraction of COVID cases do not show symptoms, but all of the studies considered here tested only symptomatic cases. This means that the probability of testing positive (which what we observe) isn't the same as the SAR $\\theta_i$! \n",
    "\n",
    "The estimates of the asymptomatic rate fall in the range $[0.18, 0.43]$. We assume a prior $A\\sim Uniform(0.18, 0.43)$. This means that the probability that a person in a study tests positive is really $\\theta_i*(1-A)$. Hence:\n",
    "\n",
    "$$X_i|\\theta_i, A \\sim Binomial(N_i, \\theta_i\\cdot (1 - A))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Complete the `approximate_inference_asympotmatic_MCMC` function to add dependence on the asymptomatic rate:\n",
    "\n",
    "*Hint: You may need to do a search to find the right distribution to use (instead of `pm.Binomial`, etc. above).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n",
    "    \"\"\"\n",
    "    Creates and fits a PyMC3 model corresponding to the graphical model above\n",
    "    \n",
    "    Inputs:\n",
    "        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n",
    "        study_df : DataFrame containing study data\n",
    "    \n",
    "    Outputs: (model, trace)\n",
    "    \"\"\"\n",
    "    with pm.Model() as model:\n",
    "        theta = ...\n",
    "        A = ...\n",
    "        X = ...\n",
    "        \n",
    "        trace = pm.sample(500, tune=1000, target_accept=0.95)\n",
    "    return (model, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `trace` now contains samples for both `theta` and `A`!\n",
    "\n",
    "Plot a histogram of the posterior estimates for $A$ if $\\alpha=5$ and $\\beta=10$. Assuming the model we defined is correct, what can you conclude about the asymptomatic rate $A$ based on the studies and the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in\n",
    "plt.hist(..., bins=...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO:` fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation tests: Do not modify\n",
    "model_test, trace_test = approximate_inference_asympotmatic_MCMC(5, 10)\n",
    "post_samples_test = trace_test['theta']\n",
    "estimates = np.mean(post_samples_test, axis = 0)\n",
    "rounded_estimates = np.round(estimates / 2, 2) * 2\n",
    "\n",
    "hash_list = ['afbc48a7ca8d716f9efa7cc993316668',\n",
    "             'e85b79abfd76b7c13b1334d8d8c194a5',\n",
    "             '0bd1ed7e9617a4ed139b2f4014c7aa23',\n",
    "             'afbc48a7ca8d716f9efa7cc993316668',\n",
    "             '4a42799b212019a2db0b77644e33790c',\n",
    "             '964e2b882801bd4ba988904454316d76',\n",
    "             '964e2b882801bd4ba988904454316d76',\n",
    "             '4a42799b212019a2db0b77644e33790c',\n",
    "             '45efc23f34e05a9ea4f5024988047dd6',\n",
    "             '451d13a5be2581a451c2284dcecddd4e',\n",
    "             '2363c78ab7dba59b8443d958b47cfa2b',\n",
    "             '0bd1ed7e9617a4ed139b2f4014c7aa23']\n",
    "\n",
    "print()\n",
    "\n",
    "for i, est in enumerate(estimates):\n",
    "    print(\"Study {}: {:.3f} \".format(i, est))\n",
    "    \n",
    "for hash_val, est in zip(hash_list, rounded_estimates):\n",
    "    assert hash_val == get_hash(est, 2)\n",
    "    \n",
    "print(\"Test passed! You are awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('baby_donkey.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "imgplot.axes.get_xaxis().set_visible(False)\n",
    "imgplot.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "history": [
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nprint(study_df)",
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "idx": 4,
    "time": "2021-02-08T01:45:21.525Z",
    "type": "execution"
   },
   {
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "time": "2021-02-08T01:45:21.656Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "48852b49462346799b20a02653a3f7ee",
    "idx": 2,
    "time": "2021-02-08T01:45:24.699Z",
    "type": "execution"
   },
   {
    "id": "48852b49462346799b20a02653a3f7ee",
    "time": "2021-02-08T01:45:25.872Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nprint(study_df)",
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "idx": 4,
    "time": "2021-02-08T01:45:26.566Z",
    "type": "execution"
   },
   {
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "time": "2021-02-08T01:45:26.648Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "idx": 4,
    "time": "2021-02-08T01:45:30.742Z",
    "type": "execution"
   },
   {
    "id": "98d08acb80b94e6a81410c32f43d509a",
    "time": "2021-02-08T01:45:30.834Z",
    "type": "completion"
   },
   {
    "code": "# TODO: Complete the function\ndef trivial_theta_estimate(N_value, X_value):\n    \"\"\"\n    Computes the trivial estimate of the Secondary Attack Rate\n    \n    Inputs:\n        N_value : int, number of susceptible individuals\n        X_value : int, number of infected individuals\n        \n    Output:\n        theta_est : float, estimate of probability of infection (SAR)\n    \"\"\"\n    theta_est = X_value / N_value\n    return theta_est",
    "id": "70c92b5478b14c76b745ca302fc2854a",
    "idx": 6,
    "time": "2021-02-08T01:46:05.924Z",
    "type": "execution"
   },
   {
    "id": "70c92b5478b14c76b745ca302fc2854a",
    "time": "2021-02-08T01:46:05.992Z",
    "type": "completion"
   },
   {
    "code": "# Validation tests\nn_test_array = [10, 100, 1000]\nx_test_array = [10, 34, 852]\nres_array = [trivial_theta_estimate(n, x_test_array[i]) for i,n in enumerate(n_test_array)]\nhash_list=['e4c2e8edac362acab7123654b9e73432','149dd5056939405870c9bb50cbc8691c','83659da620f470d5a131b5a9c76cfee7']\nfor i,res in enumerate(res_array):\n    assert get_hash(res) == hash_list[i]\nprint('Test passed!')",
    "id": "627f116799c643978599783de4633210",
    "idx": 7,
    "time": "2021-02-08T01:46:06.276Z",
    "type": "execution"
   },
   {
    "id": "627f116799c643978599783de4633210",
    "time": "2021-02-08T01:46:06.364Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:46:08.777Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:46:08.849Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:46:39.082Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:46:39.154Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)\nstudy_df",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:46:42.922Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:46:43.008Z",
    "type": "completion"
   },
   {
    "code": "# Apply  'trivial_theta_estimate' to each row of the dataframe and add a new column to hold the result\nstudy_df['Trivial estimate'] = study_df.apply(lambda row: trivial_theta_estimate(row['N'], row['X']), axis =1)\nstudy_df.sort_values('Trivial estimate')",
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "idx": 8,
    "time": "2021-02-08T01:56:27.959Z",
    "type": "execution"
   },
   {
    "id": "7f84c92bb1164fee8263d78cd4fb4ff3",
    "time": "2021-02-08T01:56:28.045Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "a42f6a40d8f74c198ed28524a6b1fc16",
    "idx": 34,
    "time": "2021-02-08T01:58:15.629Z",
    "type": "execution"
   },
   {
    "id": "a42f6a40d8f74c198ed28524a6b1fc16",
    "time": "2021-02-08T01:58:16.607Z",
    "type": "completion"
   },
   {
    "code": "!conda install m2w64-toolchain",
    "id": "6ecb21aa25c2418a89f224d6c4d1afbf",
    "idx": 35,
    "time": "2021-02-08T02:01:10.488Z",
    "type": "execution"
   },
   {
    "id": "6ecb21aa25c2418a89f224d6c4d1afbf",
    "time": "2021-02-08T02:01:52.977Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        X = pm.Binomial('X', p=theta, observed=study_df['X'], n=study_df['N'])\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "868b271973784e618e5bbe1d9172e216",
    "idx": 36,
    "time": "2021-02-08T02:34:53.853Z",
    "type": "execution"
   },
   {
    "id": "868b271973784e618e5bbe1d9172e216",
    "time": "2021-02-08T02:34:53.947Z",
    "type": "completion"
   },
   {
    "code": "### Hence $\\theta_i|X_i \\sim Beta(\\alpha + X_i, \\beta + N_i - X_i)$\n\n\nThe fact that the posterior probability comes from the same distribution family is known as *conjugacy*. It is a very useful property because it allows us to compute the posteriors in close form.",
    "id": "deca41d2e4b84fec861ac56ded06ec73",
    "idx": 15,
    "time": "2021-02-08T19:05:32.466Z",
    "type": "execution"
   },
   {
    "id": "deca41d2e4b84fec861ac56ded06ec73",
    "time": "2021-02-08T19:05:32.577Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel('Support')\n    plt.title('$\\\\theta_i \\sim Beta(\\\\alpha, \\\\beta)$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:25:25.645Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:25:25.740Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel('Support')\n    plt.title(r'$\\theta_i \\sim Beta(\\alpha, \\beta)$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:25:33.904Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:25:33.991Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:25:35.031Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:25:35.187Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "idx": 2,
    "time": "2021-02-08T19:25:39.740Z",
    "type": "execution"
   },
   {
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "time": "2021-02-08T19:25:41.040Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:25:48.347Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:25:48.883Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0, 1.01, 0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i')\n    plt.ylabel(r'$p(\\theta_i)')\n    plt.title(r'Beta distribution with parameters $\\alpha and $\\beta')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:27:17.114Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:27:17.212Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:27:18.530Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:27:18.894Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0, 1.01, 0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i')\n    plt.ylabel(r'$p(\\theta_i)')\n    plt.title(r'Beta distribution with parameters $\\alpha$ and $\\beta$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:27:26.398Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:27:26.489Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:27:28.387Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:27:28.872Z",
    "type": "completion"
   },
   {
    "code": "def plot_beta(alpha_value, beta_value):\n    x = np.arange(0, 1.01, 0.01)\n    y = beta.pdf(x, alpha_value, beta_value)\n    fig = plt.figure()\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.ylabel(r'$p(\\theta_i)$')\n    plt.title(r'Beta distribution with parameters $\\alpha$ and $\\beta$')\n    plt.ylim(0, 10)\n    plt.show() ",
    "id": "cbf26d1a261840398400ac265ad3830d",
    "idx": 17,
    "time": "2021-02-08T19:27:38.158Z",
    "type": "execution"
   },
   {
    "id": "cbf26d1a261840398400ac265ad3830d",
    "time": "2021-02-08T19:27:38.250Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_beta, alpha_value=(1, 20, 0.5), beta_value=(1,20, 0.5))\ninteractive_plot",
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "idx": 18,
    "time": "2021-02-08T19:27:38.399Z",
    "type": "execution"
   },
   {
    "id": "77feae32fac34bc2bdc53eb833d47f24",
    "time": "2021-02-08T19:27:38.793Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef posterior_mean_estimate(N_value, X_value, alpha_value, beta_value):\n    \"\"\"\n    Computes the posterior E[theta_i|X_i] when we consider a prior theta_i ~ Beta(alpha, beta)\n    \n    Inputs: \n        N_value : int, total number of susceptible individuals\n        X_value : int, number of individuals that became infected\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n    \"\"\"\n    posterior_mean = (alpha_value + X_value)/(alpha_value + beta_value + N_value)\n    return posterior_mean\n    ",
    "id": "cc81886d0ba744f09424be07164de36d",
    "idx": 26,
    "time": "2021-02-08T19:30:35.348Z",
    "type": "execution"
   },
   {
    "id": "cc81886d0ba744f09424be07164de36d",
    "time": "2021-02-08T19:30:35.445Z",
    "type": "completion"
   },
   {
    "code": "# Validation tests\nN_test = 100\nX_test = 20\nalpha_test_array = [1, 10, 100]\nbeta_test_array = [1, 10, 100]\ninputs = list(itertools.product(alpha_test_array, beta_test_array))\nhash_list = ['8ae3cf8f9366cbdea2ccf7706546ba4a','f8ddc3234c0a54e55b01384bcfb23f90','82589ee1f18a2e0b9fe9d14836983102',\n             '08cf5a2033e7e21ec90b6707c24facaf','70da82175ec8a195a3d8b0fa8f69681d','ced20bed08ecfba035cbc3e06657cff2',\n             'c8a7feeaced214c662a999d9bf075e8c','790abc5c38e7c740420b03c24fabb05b','54fbf38cf649866815e0fefc46a1f6c7']\nfor i,inp in enumerate(inputs):\n    assert hash_list[i] == get_hash(posterior_mean_estimate(N_test, X_test, *inp))\nprint('Test passed!')",
    "id": "7e04e7f5526340478eb38b0bacfb5e97",
    "idx": 27,
    "time": "2021-02-08T19:30:36.118Z",
    "type": "execution"
   },
   {
    "id": "7e04e7f5526340478eb38b0bacfb5e97",
    "time": "2021-02-08T19:30:36.206Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='k', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3,  ls=\"--\", color='k', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel('Support')\n    plt.title('Prior $\\\\theta_i \\sim Beta(\\\\alpha={}, \\\\beta={})$'.format(k, 2*k))\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 29,
    "time": "2021-02-08T19:33:23.429Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:33:23.551Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 30,
    "time": "2021-02-08T19:33:27.715Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:33:27.943Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 4,
    "time": "2021-02-08T19:33:33.958Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-08T19:33:34.085Z",
    "type": "completion"
   },
   {
    "code": "# TODO: Complete the function\ndef trivial_theta_estimate(N_value, X_value):\n    \"\"\"\n    Computes the trivial estimate of the Secondary Attack Rate\n    \n    Inputs:\n        N_value : int, number of susceptible individuals\n        X_value : int, number of infected individuals\n        \n    Output:\n        theta_est : float, estimate of probability of infection (SAR)\n    \"\"\"\n    theta_est = X_value / N_value\n    return theta_est",
    "id": "401bb627b4ef4b958b4ec823f8abff47",
    "idx": 6,
    "time": "2021-02-08T19:33:36.113Z",
    "type": "execution"
   },
   {
    "id": "401bb627b4ef4b958b4ec823f8abff47",
    "time": "2021-02-08T19:33:36.203Z",
    "type": "completion"
   },
   {
    "code": "# Validation tests\nn_test_array = [10, 100, 1000]\nx_test_array = [10, 34, 852]\nres_array = [trivial_theta_estimate(n, x_test_array[i]) for i,n in enumerate(n_test_array)]\nhash_list=['e4c2e8edac362acab7123654b9e73432','149dd5056939405870c9bb50cbc8691c','83659da620f470d5a131b5a9c76cfee7']\nfor i,res in enumerate(res_array):\n    assert get_hash(res) == hash_list[i]\nprint('Test passed!')",
    "id": "4c9161d63a544fdb81afcf680ba6d79a",
    "idx": 7,
    "time": "2021-02-08T19:33:36.277Z",
    "type": "execution"
   },
   {
    "id": "4c9161d63a544fdb81afcf680ba6d79a",
    "time": "2021-02-08T19:33:36.372Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 33,
    "time": "2021-02-08T19:37:48.067Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:37:49.164Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='k', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3,  ls=\"--\", color='k', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.title(rf'Prior $\\theta_i \\sim Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 32,
    "time": "2021-02-08T19:39:24.819Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:39:24.916Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 33,
    "time": "2021-02-08T19:39:26.321Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:39:27.398Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3,  ls=\"--\", color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.title(rf'Prior $\\theta_i \\sim Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 32,
    "time": "2021-02-08T19:39:43.150Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:39:43.244Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3, ls=\"--\", color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.title(rf'Prior $\\theta_i \\sim Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 32,
    "time": "2021-02-08T19:39:45.930Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:39:46.021Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 33,
    "time": "2021-02-08T19:39:46.343Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:39:47.483Z",
    "type": "completion"
   },
   {
    "code": "study_df",
    "id": "8f9339ade53a48bfbea36e2a7c247330",
    "idx": 32,
    "time": "2021-02-08T19:41:29.560Z",
    "type": "execution"
   },
   {
    "id": "8f9339ade53a48bfbea36e2a7c247330",
    "time": "2021-02-08T19:41:29.677Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3, ls=\"--\", color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.ylabel(r'$p(\\theta_i)$')\n    plt.title(rf'Prior: $Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 33,
    "time": "2021-02-08T19:43:27.378Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:43:27.483Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 34,
    "time": "2021-02-08T19:43:29.047Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:43:30.103Z",
    "type": "completion"
   },
   {
    "code": "interactive?",
    "id": "993cc627c81343fbb20bd76ccf80b5ae",
    "idx": 34,
    "time": "2021-02-08T19:43:38.208Z",
    "type": "execution"
   },
   {
    "id": "993cc627c81343fbb20bd76ccf80b5ae",
    "time": "2021-02-08T19:43:38.356Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Examine the code\ndef plot_thetas(k):\n    \n    study_df[\"bayesian_theta\"] = study_df.apply(\n        lambda row: posterior_mean_estimate(row['N'], row['X'], k, 2*k), \n        axis=1\n    )\n    study_df[\"trivial_theta\"] = study_df.apply(\n        lambda row: trivial_theta_estimate(row['N'], row['X']), \n        axis=1\n    )\n    fig = plt.figure(figsize=(14, 6))\n    plt.subplot(1, 2, 1)\n    graph = sns.scatterplot(\n        x=\"trivial_theta\", y=\"bayesian_theta\", \n        data=study_df, size=\"N\", sizes=(50, 300), alpha=.8\n    )\n    sns.lineplot(\n        x='trivial_theta', y='trivial_theta', \n        data= study_df, ls=\"--\", color='black', lw=1\n    )\n    plt.ylim(0.16, 0.52)\n    graph.axhline(\n        1/3, color='black', \n        label = \"$\\frac{1}{3}$ Prior Expectation\"\n    )\n    plt.xlabel('Trivial Estimate')\n    plt.ylabel('Posterior Mean Estimate')\n    \n    plt.subplot(1, 2, 2)\n    x = np.arange(0,1.01,0.01)\n    y = beta.pdf(x, k, 2*k)\n    plt.plot(x, y)\n    plt.xlabel(r'$\\theta_i$')\n    plt.ylabel(r'$p(\\theta_i)$')\n    plt.title(rf'Prior: $Beta(\\alpha={k}, \\beta={2*k})$')\n    plt.ylim(0, 10)\n    plt.show()",
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "idx": 33,
    "time": "2021-02-08T19:44:39.079Z",
    "type": "execution"
   },
   {
    "id": "4ae4cbd0f6cf49a6816f56d9594173b3",
    "time": "2021-02-08T19:44:39.185Z",
    "type": "completion"
   },
   {
    "code": "interactive_plot = interactive(plot_thetas, k=(0, 50, 2))\ninteractive_plot",
    "id": "f74e8441886d46c3826522181164423f",
    "idx": 34,
    "time": "2021-02-08T19:44:39.620Z",
    "type": "execution"
   },
   {
    "id": "f74e8441886d46c3826522181164423f",
    "time": "2021-02-08T19:44:40.670Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-08T19:50:30.791Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-08T19:50:31.332Z",
    "type": "completion"
   },
   {
    "code": "!pip uninstall Theano Theano-PyMC pymc3  -y\n!pip install 'Theano==1.0.5'\n!pip install 'pymc3==3.11.0'\nimport pymc3",
    "id": "2b050c30ee02497d8fe823b6df8136c3",
    "idx": 45,
    "time": "2021-02-08T19:50:50.744Z",
    "type": "execution"
   },
   {
    "id": "2b050c30ee02497d8fe823b6df8136c3",
    "time": "2021-02-08T19:51:13.549Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "3a5117ca2bd840358e70b83be38ef877",
    "idx": 46,
    "time": "2021-02-08T19:52:21.129Z",
    "type": "execution"
   },
   {
    "id": "3a5117ca2bd840358e70b83be38ef877",
    "time": "2021-02-08T19:52:24.689Z",
    "type": "completion"
   },
   {
    "code": "!pip freeze",
    "id": "fc9502c4c76545c2a568367195cb37b2",
    "idx": 46,
    "time": "2021-02-08T19:52:36.184Z",
    "type": "execution"
   },
   {
    "id": "fc9502c4c76545c2a568367195cb37b2",
    "time": "2021-02-08T19:52:37.866Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-08T19:59:52.511Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-08T19:59:52.614Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a \n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution, tuning\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 46,
    "time": "2021-02-08T20:03:55.725Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-08T20:03:56.277Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 4,
    "time": "2021-02-08T20:04:05.094Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-08T20:04:05.202Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "idx": 2,
    "time": "2021-02-08T20:04:09.493Z",
    "type": "execution"
   },
   {
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "time": "2021-02-08T20:04:09.670Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 4,
    "time": "2021-02-08T20:04:12.482Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-08T20:04:12.624Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a \n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution, tuning\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 46,
    "time": "2021-02-08T20:04:33.106Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-08T20:04:33.201Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef fit_approximate_inference(\n    alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the\n    graphical model in Q.1\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of\n        the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a \n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return(model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 46,
    "time": "2021-02-08T20:07:39.817Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-08T20:07:39.910Z",
    "type": "completion"
   },
   {
    "code": "m, t = fit_approximate_inference()",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 47,
    "time": "2021-02-08T20:07:47.617Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-08T20:07:47.724Z",
    "type": "completion"
   },
   {
    "code": "m, t = fit_approximate_inference(10, 20)",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 47,
    "time": "2021-02-08T20:08:03.413Z",
    "type": "execution"
   },
   {
    "code": "3",
    "id": "579de7599db744479362e454ea7086c4",
    "idx": 48,
    "time": "2021-02-08T20:08:41.656Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-08T20:08:46.795Z",
    "type": "completion"
   },
   {
    "id": "579de7599db744479362e454ea7086c4",
    "time": "2021-02-08T20:08:46.796Z",
    "type": "completion"
   },
   {
    "code": "m, t = fit_approximate_inference(10, 20)",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 47,
    "time": "2021-02-08T20:09:10.678Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-08T20:11:19.036Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify\ndef sample_posterior_theta(model, trace):\n    \"\"\"\n    Return samples from the posterior distribution theta_i|X_i\n    \n    Inputs:\n        models, trace : PyPM3 objects, outputs of fit_approximate_inference\n        \n    Output:\n        posterior_samples : (2000 x num_studies array), each column contains posterior samples for a theta_i\n    \"\"\"\n    with model:\n        posterior_samples = pm.sample_posterior_predictive(trace, var_names=[\"theta\"], random_seed=0)['theta']\n    return(posterior_samples)   ",
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "idx": 48,
    "time": "2021-02-08T20:11:25.034Z",
    "type": "execution"
   },
   {
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "time": "2021-02-08T20:11:25.136Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify\ndef sample_posterior_theta(model, trace):\n    \"\"\"\n    Return samples from the posterior distribution theta_i|X_i\n    \n    Inputs:\n        models, trace : PyPM3 objects, outputs of fit_approximate_inference\n        \n    Output:\n        posterior_samples : (2000 x num_studies array), each column contains \n            2000 posterior samples for a theta_i\n    \"\"\"\n    with model:\n        posterior_samples = pm.sample_posterior_predictive(\n            trace, var_names=[\"theta\"], random_seed=0\n        )['theta']\n        posterior_theta_samples = posterior_samples['theta']\n    return(posterior_theta_samples)   ",
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "idx": 48,
    "time": "2021-02-08T20:12:39.506Z",
    "type": "execution"
   },
   {
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "time": "2021-02-08T20:12:39.603Z",
    "type": "completion"
   },
   {
    "code": "theta_samples = sample_posterior_theta(m, t)",
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "idx": 49,
    "time": "2021-02-08T20:12:48.357Z",
    "type": "execution"
   },
   {
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "time": "2021-02-08T20:12:48.877Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify\ndef sample_posterior_theta(model, trace):\n    \"\"\"\n    Return samples from the posterior distribution theta_i|X_i\n    \n    Inputs:\n        models, trace : PyPM3 objects, outputs of fit_approximate_inference\n        \n    Output:\n        posterior_samples : (2000 x num_studies array), each column contains \n            2000 posterior samples for a theta_i\n    \"\"\"\n    with model:\n        posterior_samples = pm.sample_posterior_predictive(\n            trace, var_names=[\"theta\"], random_seed=0\n        )\n        posterior_theta_samples = posterior_samples['theta']\n    return(posterior_theta_samples)   ",
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "idx": 48,
    "time": "2021-02-08T20:12:56.931Z",
    "type": "execution"
   },
   {
    "id": "a58b607dbda44b1ab82a141408d30de5",
    "time": "2021-02-08T20:12:57.032Z",
    "type": "completion"
   },
   {
    "code": "theta_samples = sample_posterior_theta(m, t)",
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "idx": 49,
    "time": "2021-02-08T20:12:57.134Z",
    "type": "execution"
   },
   {
    "id": "ab2448cd7a0140019aa3237d4588a5cd",
    "time": "2021-02-08T20:12:57.418Z",
    "type": "completion"
   },
   {
    "code": "theta_samples",
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "idx": 50,
    "time": "2021-02-08T20:13:00.281Z",
    "type": "execution"
   },
   {
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "time": "2021-02-08T20:13:00.396Z",
    "type": "completion"
   },
   {
    "code": "theta_samples.shape",
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "idx": 50,
    "time": "2021-02-08T20:13:03.420Z",
    "type": "execution"
   },
   {
    "id": "ae34ae7f733a439e8abe156ebc26cbfd",
    "time": "2021-02-08T20:13:03.510Z",
    "type": "completion"
   },
   {
    "code": "pm.sample?",
    "id": "be21c5e4bf4e438e81ac7ae2c5bb4811",
    "idx": 47,
    "time": "2021-02-08T20:13:16.278Z",
    "type": "execution"
   },
   {
    "id": "be21c5e4bf4e438e81ac7ae2c5bb4811",
    "time": "2021-02-08T20:13:16.502Z",
    "type": "completion"
   },
   {
    "code": "import pymc3 as pm\nwith pm.Model() as model:\n    dummy = pm.Beta('dummy', alpha=1, beta=1)\n    pm.sample(1)",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-08T20:14:33.066Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-08T20:15:31.525Z",
    "type": "completion"
   },
   {
    "code": "t",
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "idx": 48,
    "time": "2021-02-08T20:17:16.107Z",
    "type": "execution"
   },
   {
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "time": "2021-02-08T20:17:16.209Z",
    "type": "completion"
   },
   {
    "code": "t['theta']",
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "idx": 48,
    "time": "2021-02-08T20:17:21.216Z",
    "type": "execution"
   },
   {
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "time": "2021-02-08T20:17:21.478Z",
    "type": "completion"
   },
   {
    "code": "t['theta']",
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "idx": 48,
    "time": "2021-02-08T20:17:44.832Z",
    "type": "execution"
   },
   {
    "id": "81f83e7db0b64e64853f2fc0d80e059e",
    "time": "2021-02-08T20:17:44.921Z",
    "type": "completion"
   },
   {
    "code": "sample_posterior_theta(m, t)",
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "idx": 49,
    "time": "2021-02-08T20:17:51.608Z",
    "type": "execution"
   },
   {
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "time": "2021-02-08T20:17:51.850Z",
    "type": "completion"
   },
   {
    "code": "np.allclose(sample_posterior_theta(m, t), t['theta']",
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "idx": 49,
    "time": "2021-02-08T20:18:01.477Z",
    "type": "execution"
   },
   {
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "time": "2021-02-08T20:18:01.571Z",
    "type": "completion"
   },
   {
    "code": "np.allclose(sample_posterior_theta(m, t), t['theta'])",
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "idx": 49,
    "time": "2021-02-08T20:18:03.681Z",
    "type": "execution"
   },
   {
    "id": "7a951c5388dd4b148f4122d49b1d7714",
    "time": "2021-02-08T20:18:03.942Z",
    "type": "completion"
   },
   {
    "code": "# TODO: fill in",
    "id": "22fb656a622640bd8520ad9f2421211f",
    "idx": 51,
    "time": "2021-02-08T20:26:54.269Z",
    "type": "execution"
   },
   {
    "id": "22fb656a622640bd8520ad9f2421211f",
    "time": "2021-02-08T20:26:54.366Z",
    "type": "completion"
   },
   {
    "code": "# Import PyMC3, and create a dummy model so that one-time initialization\n# happens while you're reading over the code in the next cell.\n\n# You can ignore the output of this cell.\n\nimport pymc3 as pm\nwith pm.Model() as model:\n    dummy = pm.Beta('dummy', alpha=1, beta=1)\n    pm.sample(1)",
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "idx": 45,
    "time": "2021-02-09T00:19:23.222Z",
    "type": "execution"
   },
   {
    "id": "faee0d0a19384cc29b1970bc576cd05b",
    "time": "2021-02-09T00:19:35.436Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        AR = pm.Uniform('AR', lower = 0.18, upper = 0.43)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:51:34.807Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:51:34.966Z",
    "type": "completion"
   },
   {
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import beta, binom\nimport itertools\nfrom ipywidgets import interact, interactive\n\nimport hashlib\n%matplotlib inline\n\nsns.set(style=\"dark\")\nplt.style.use(\"ggplot\")\n\ndef get_hash(num, significance = 4):\n    num = round(num, significance)\n    \"\"\"Helper function for assessing correctness\"\"\"\n    return hashlib.md5(str(num).encode()).hexdigest()",
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "idx": 2,
    "time": "2021-02-09T00:51:40.232Z",
    "type": "execution"
   },
   {
    "id": "9776312796dd4630b0e3d0f1e216f056",
    "time": "2021-02-09T00:51:40.407Z",
    "type": "completion"
   },
   {
    "code": "# Read out a dataset \nstudy_df = pd.read_csv(\"study_df.csv\", header=0)\nstudy_df",
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "idx": 13,
    "time": "2021-02-09T00:51:45.190Z",
    "type": "execution"
   },
   {
    "id": "09e298c206fb40b39f478dbd5e1183ac",
    "time": "2021-02-09T00:51:45.309Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        AR = pm.Uniform('AR', lower = 0.18, upper = 0.43)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:51:49.067Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:51:49.166Z",
    "type": "completion"
   },
   {
    "code": "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)",
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "idx": 77,
    "time": "2021-02-09T00:52:13.708Z",
    "type": "execution"
   },
   {
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "time": "2021-02-09T00:53:03.903Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['AR'])",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:53:16.177Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:53:16.586Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['AR'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:53:32.686Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:53:33.211Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        #theta = # TODO: fill in\n        #A = # TODO: fill in\n        #X = # TODO: fill in\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        A = pm.Uniform('AR', lower = 0.18, upper = 0.43)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        \n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:56:36.221Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:56:36.317Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        #theta = # TODO: fill in\n        #A = # TODO: fill in\n        #X = # TODO: fill in\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        A = pm.Uniform('A', lower = 0.05, upper = 0.73)\n        X = pm.Binomial('X', p=theta*(1-AR), observed=study_df['X'], n=study_df['N'])\n        \n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:56:54.389Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:56:54.486Z",
    "type": "completion"
   },
   {
    "code": "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)",
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "idx": 77,
    "time": "2021-02-09T00:56:55.855Z",
    "type": "execution"
   },
   {
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "time": "2021-02-09T00:56:56.860Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['AR'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:56:56.889Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:56:57.360Z",
    "type": "completion"
   },
   {
    "code": "# TODO: complete the function\ndef approximate_inference_asympotmatic_MCMC(alpha_value, beta_value, study_df = study_df):\n    \"\"\"\n    Creates and fits a PyMC3 model corresponding to the graphical model above\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n    \"\"\"\n    with pm.Model() as model:\n        #theta = # TODO: fill in\n        #A = # TODO: fill in\n        #X = # TODO: fill in\n        theta = pm.Beta('theta', alpha=alpha_value, beta=beta_value, shape=len(study_df))\n        A = pm.Uniform('A', lower = 0.05, upper = 0.73)\n        X = pm.Binomial('X', p=theta*(1-A), observed=study_df['X'], n=study_df['N'])\n        \n        trace = pm.sample(500, tune=1000, target_accept=0.95)\n    return (model, trace)",
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "idx": 75,
    "time": "2021-02-09T00:57:20.468Z",
    "type": "execution"
   },
   {
    "id": "23efc8ac8c104a5f8c8eaf3f79a9bb8a",
    "time": "2021-02-09T00:57:20.563Z",
    "type": "completion"
   },
   {
    "code": "model, trace = approximate_inference_asympotmatic_MCMC(5, 10)",
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "idx": 77,
    "time": "2021-02-09T00:57:21.716Z",
    "type": "execution"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:57:26.582Z",
    "type": "execution"
   },
   {
    "id": "0ca1a2d88898426280dc3f7093aaf870",
    "time": "2021-02-09T00:57:36.845Z",
    "type": "completion"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:57:37.266Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.18, .43, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:57:49.598Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:57:50.177Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.05, .y3, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:58:00.045Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:58:00.131Z",
    "type": "completion"
   },
   {
    "code": "plt.hist(trace['A'], bins=np.linspace(.05, .73, 100))",
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "idx": 78,
    "time": "2021-02-09T00:58:03.081Z",
    "type": "execution"
   },
   {
    "code": "# TODO: fill in",
    "id": "f7c5a6ee8d044211a7dbb52cf13c2525",
    "idx": 79,
    "time": "2021-02-09T00:58:03.536Z",
    "type": "execution"
   },
   {
    "id": "9f4909a1a5e64d4ea1570194a0012755",
    "time": "2021-02-09T00:58:03.615Z",
    "type": "completion"
   },
   {
    "id": "f7c5a6ee8d044211a7dbb52cf13c2525",
    "time": "2021-02-09T00:58:03.683Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n\"\"\"\n    Plots for each study the prior distribution, theoretical posterior \n    and histogram of empirical posterior samples\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            ax = axs[i, j]\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior_y = beta.pdf(x_array, alpha_value+X_i, beta_value+N_i-X_i)\n            ax.plot(x_array, prior_y, label = 'Prior')\n            ax.plot(x_array, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(posterior_theta_samples[:,idx], label = \"Empirical Posterior\", density='True', alpha = 0.5)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:02:09.390Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:02:09.508Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:02:09.562Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:02:09.959Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, theoretical posterior \n    and histogram of empirical posterior samples\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            ax = axs[i, j]\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior_y = beta.pdf(x_array, alpha_value+X_i, beta_value+N_i-X_i)\n            ax.plot(x_array, prior_y, label = 'Prior')\n            ax.plot(x_array, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(posterior_theta_samples[:,idx], label = \"Empirical Posterior\", density='True', alpha = 0.5)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:02:23.636Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:02:23.996Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = fit_approximate_inference(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:05:03.052Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:05:03.148Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:05:03.809Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:05:06.520Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:06:24.240Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:06:24.342Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:06:24.580Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:06:27.461Z",
    "type": "completion"
   },
   {
    "code": "# Do not modify: Spend some time examining the code\ndef approximate_inference_MCMC(\n    alpha_value, beta_value, study_df = study_df\n):\n    \"\"\"\n    Creates and generates samples from a PyMC3 model of\n    the posterior distribution that corresponds to the\n    graphical model in Q.1, using Markov Chain Monte Carlo (MCMC)\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of\n        the prior Beta Distribution\n        study_df : DataFrame containing study data\n    \n    Outputs: (model, trace)\n        model is a PyMC3 model object, which represents the graphical model\n        trace is a PyMC3 trace object, which represents 2000 samples\n            of everything from the posterior\n    \"\"\"\n    # Defines the graphical model\n    with pm.Model() as model:\n        # The prior for theta is a Beta distribution with parameters\n        # alpha and beta, and there's one for each study.\n        theta = pm.Beta(\n            'theta', alpha=alpha_value, beta=beta_value, \n            shape=len(study_df)\n        )\n        \n        # The likelihood for X is binomial, with parameter p=theta,\n        # observed counts in study_df['X'], and observed N similarly\n        X = pm.Binomial(\n            'X', p=theta, observed=study_df['X'], n=study_df['N']\n        )\n        \n        # Generate samples from the posterior distribution using : run 4\n        # Markov chains of sampling in parallel, generating 500 samples\n        # each.\n        trace = pm.sample(500, chains=4, tune=1000, target_accept=0.95)\n    \n    return (model, trace)",
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "idx": 55,
    "time": "2021-02-09T01:06:32.712Z",
    "type": "execution"
   },
   {
    "id": "486dbc1b85734a84a6389acfc4d7b62b",
    "time": "2021-02-09T01:06:32.806Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            theoretical_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, theoretical_posterior_y, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:06:35.842Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:06:35.939Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:06:38.627Z",
    "type": "execution"
   },
   {
    "code": "# Plot the resulting densities for a strong prior\nfig2 = plot_densities(20, 40, study_df = study_df)",
    "id": "21069a4809fb46408f18c362be53a79d",
    "idx": 68,
    "time": "2021-02-09T01:06:45.412Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:06:56.288Z",
    "type": "completion"
   },
   {
    "id": "21069a4809fb46408f18c362be53a79d",
    "time": "2021-02-09T01:06:56.290Z",
    "type": "completion"
   },
   {
    "code": "# TODO: write the plotting function\ndef plot_densities(alpha_value, beta_value, study_df = study_df): \n    \"\"\"\n    Plots for each study the prior distribution, true posterior,\n    and histogram of posterior samples using MCMC\n    \n    Inputs:\n        alpha_value, beta_value : floats, parameters of the prior Beta Distribution\n        study_df : DataFrame containing study data\n        \n    Outputs:\n        fig : Figure with 12 subplots\n    \"\"\"\n    fig, axs = plt.subplots(4, 3)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n\n    \n    theta = np.arange(0, 1.01, 0.01)\n    prior = beta.pdf(theta, alpha_value, beta_value)\n    \n    model, trace = approximate_inference_MCMC(alpha_value, beta_value, study_df)\n    samples = trace['theta']\n    \n    for i in range(4):\n        for j in range(3):\n            idx = 3*i+ j\n            X_i = study_df.loc[idx, 'X']\n            N_i = study_df.loc[idx, 'N']\n            study_name = f'Study {idx}'\n            true_posterior = beta.pdf(theta, alpha_value+X_i, beta_value+N_i-X_i)\n            \n            ax = axs[i, j]\n            ax.plot(theta, prior, label = 'Prior')\n            ax.plot(theta, true_posterior, label = \"Theoretical Posterior\")\n            ax.hist(samples[:,idx], label = \"Empirical Posterior\", density=True, alpha = 0.7)\n            ax.set_title(study_name)\n            ax.legend()\n    \n    plt.tight_layout()        \n    plt.show()\n    return fig",
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "idx": 66,
    "time": "2021-02-09T01:07:26.519Z",
    "type": "execution"
   },
   {
    "id": "9dac4bffed774a63b0f717b1ba04a3b0",
    "time": "2021-02-09T01:07:26.623Z",
    "type": "completion"
   },
   {
    "code": "# Plot the resulting densities for a weak prior\nfig1 = plot_densities(2, 4, study_df = study_df)",
    "id": "acadef7061df45db851f4131a509c091",
    "idx": 67,
    "time": "2021-02-09T01:07:26.736Z",
    "type": "execution"
   },
   {
    "code": "# Plot the resulting densities for a strong prior\nfig2 = plot_densities(20, 40, study_df = study_df)",
    "id": "21069a4809fb46408f18c362be53a79d",
    "idx": 68,
    "time": "2021-02-09T01:07:28.251Z",
    "type": "execution"
   },
   {
    "id": "acadef7061df45db851f4131a509c091",
    "time": "2021-02-09T01:07:42.748Z",
    "type": "completion"
   },
   {
    "id": "21069a4809fb46408f18c362be53a79d",
    "time": "2021-02-09T01:07:57.595Z",
    "type": "completion"
   },
   {
    "code": "# Run approximate inference\nmodel, trace = approximate_inference_MCMC(10, 20)\n\n# Get posterior samples of theta\nthetas = trace['theta']\nthetas",
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "idx": 64,
    "time": "2021-02-09T01:14:33.260Z",
    "type": "execution"
   },
   {
    "id": "fa2d45e2febd48c383930ba9dee224dd",
    "time": "2021-02-09T01:14:42.877Z",
    "type": "completion"
   },
   {
    "code": "# TODO: fill in\nplt.hist(thetas[:, 2], density=True)",
    "id": "91ecf69958934aa48328f4c97a8f7042",
    "idx": 67,
    "time": "2021-02-09T01:14:44.946Z",
    "type": "execution"
   },
   {
    "id": "91ecf69958934aa48328f4c97a8f7042",
    "time": "2021-02-09T01:14:45.272Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
